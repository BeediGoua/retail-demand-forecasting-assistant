import streamlit as st
import sqlite3
import pandas as pd
import subprocess
import sys
from pathlib import Path

st.set_page_config(
    page_title="Retail Forecasting Assistant", 
    page_icon="üìä", 
    layout="wide"
)

DB_PATH = Path("data/retail.sqlite")
RAW_DATA_PATH = Path("data/raw/train.csv")

def check_database_exists():
    """V√©rifie si la base de donn√©es existe et est valide"""
    if not DB_PATH.exists():
        return False
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM fact_sales_weekly")
        count = cursor.fetchone()[0]
        conn.close()
        return count > 0
    except:
        return False

def check_raw_data_exists():
    """V√©rifie si les donn√©es brutes sont pr√©sentes"""
    return RAW_DATA_PATH.exists()

def build_database():
    """Lance le pipeline de construction de la base de donn√©es"""
    with st.spinner("√âtape 1/2 : Traitement des donn√©es (peut prendre 2-3 minutes)..."):
        result = subprocess.run(
            [sys.executable, "scripts/preprocessing.py"],
            capture_output=True,
            text=True
        )
        if result.returncode != 0:
            st.error(f"Erreur lors du preprocessing : {result.stderr}")
            return False
    
    with st.spinner("√âtape 2/2 : Construction de la base de donn√©es..."):
        result = subprocess.run(
            [sys.executable, "scripts/build_warehouse.py"],
            capture_output=True,
            text=True
        )
        if result.returncode != 0:
            st.error(f"Erreur lors du build : {result.stderr}")
            return False
    
    return True

@st.cache_data
def get_stats():
    """R√©cup√®re les statistiques de la base de donn√©es"""
    conn = sqlite3.connect(DB_PATH)
    try:
        n_stores = pd.read_sql("SELECT COUNT(*) FROM dim_store", conn).iloc[0,0]
        n_families = pd.read_sql("SELECT COUNT(*) FROM dim_family", conn).iloc[0,0]
        n_weeks = pd.read_sql("SELECT COUNT(*) FROM dim_week", conn).iloc[0,0]
        n_sales_records = pd.read_sql("SELECT COUNT(*) FROM fact_sales_weekly", conn).iloc[0,0]
        return n_stores, n_families, n_weeks, n_sales_records
    except Exception as e:
        return 0, 0, 0, 0
    finally:
        conn.close()

# Interface principale
st.title("üìä Retail Forecasting & Inventory Assistant")
st.markdown("**Assistant d'aide √† la d√©cision pour l'optimisation des stocks**")

st.divider()

# V√©rification de l'√©tat du syst√®me
db_exists = check_database_exists()
raw_data_exists = check_raw_data_exists()

if not db_exists:
    st.warning("‚ö†Ô∏è La base de donn√©es n'est pas encore initialis√©e")
    
    if not raw_data_exists:
        st.error("‚ùå Donn√©es brutes manquantes")
        st.markdown("""
        Les fichiers CSV bruts sont introuvables dans `data/raw/`.
        
        **Pour les obtenir** :
        1. T√©l√©charger depuis Kaggle : https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data
        2. Placer les fichiers dans le dossier `data/raw/`
        """)
    else:
        st.success("‚úÖ Donn√©es brutes d√©tect√©es (119 MB)")
        
        st.markdown("""
        ### Initialisation de la Base de Donn√©es
        
        Cliquez sur le bouton ci-dessous pour construire la base de donn√©es.
        
        **Ce processus va** :
        1. Nettoyer et transformer les donn√©es brutes
        2. Cr√©er les agr√©gations hebdomadaires
        3. Construire le Data Warehouse SQL (315 MB)
        
        **Dur√©e estim√©e** : 2-3 minutes
        """)
        
        if st.button("üöÄ Initialiser la Base de Donn√©es", type="primary", use_container_width=True):
            if build_database():
                st.success("‚úÖ Base de donn√©es cr√©√©e avec succ√®s !")
                st.balloons()
                st.rerun()
            else:
                st.error("‚ùå √âchec de la construction. Consultez les logs ci-dessus.")
else:
    st.success("‚úÖ Syst√®me op√©rationnel")
    
    # Affichage des statistiques
    stores, families, weeks, sales_records = get_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Magasins", stores)
    col2.metric("Familles Produits", families)
    col3.metric("Semaines Historiques", weeks)
    col4.metric("Enregistrements Ventes", f"{sales_records:,}")
    
    st.divider()
    
    st.markdown("""
    ### √âtat du Syst√®me
    
    - ‚úÖ **Data Warehouse** : Connect√© (`retail.sqlite`)
    - üèóÔ∏è **Mod√®les** : En attente d'entra√Ænement
    - üìâ **Pr√©visions** : Non disponibles
    
    ### Prochaines √âtapes
    
    Utilisez le menu lat√©ral pour naviguer vers :
    - **Exploration des Donn√©es** : Visualiser les tendances historiques
    - **Mod√©lisation** : Entra√Æner les mod√®les de pr√©vision
    - **D√©cisions Stock** : G√©n√©rer les recommandations de commande
    
    *(Fonctionnalit√©s en d√©veloppement)*
    """)
    
    # Option de reconstruction
    with st.expander("‚öôÔ∏è Options Avanc√©es"):
        st.warning("Attention : Cette action va supprimer et reconstruire la base de donn√©es")
        if st.button("üîÑ Reconstruire la Base de Donn√©es"):
            if DB_PATH.exists():
                DB_PATH.unlink()
            st.rerun()
